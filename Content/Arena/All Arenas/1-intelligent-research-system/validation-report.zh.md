__初步验证报告__

__说明__

本文档黑字为模板与填写说明，蓝字为填写内容。

__项目名称__

研发智能调研和报告生成系统

__填写人（填写机构）__

RWAI（浙江清华长三角研究院人工智能创新研究中心）

__填写日期__

2025 年 12 月 19 日

__文档版本__

__文档状态__

\[√\]草稿   \[\]定稿

<a id="heading_0"></a>1\. __摘要__

摘要，介绍该项目的业务背景、待验证目标、结论。

- 业务背景：业务需要一套系统，实现从研究主题输入到结构化调研报告输出的自动化流程，来解决传统人工调研效率低下、信息整合难度大、报告格式不统一等行业痛点。基于业务需求，技术团队拟研发一个基于大语言模型来自动调研、搜集、整理并生成报告的“智能调研和报告生成系统”，该系统主要通过Claude Code智能体框架，集成多源搜索服务和MCP工具，包含核心模块有：查询理解、智能资料搜集、结构化信息提取、自动报告生成和质量控制等。
- 验证目标：针对所提系统，本阶段的目标是跑测、对比该系统的核心指标，确保所提方案的技术可行性、性能领先性（SOTA），并确立其重要业务价值，为后续正式立项提供依据。
- 验证结论：
- 性能：该方案在Deep Research评测基准DeepResearch Bench上跑测综合得分为51\.86，在该榜单截止2025年12月24日全部方案中排名第2位（与第1位方案tavily\-research（51\.97）综合得分差距小于1\.5%（可视为性能相当），达到了目前方案的技术领先性。
- 效率：该方案的报告平均生成时间≤15分钟，比上述第1位开源可用方案salesforce\-air\-deep\-research（平均约为20分钟）快33%，且完全满足业务预期，通过效率测评。
- 综上，该方案达成业务预期，通过可行性与领先性验证。

<a id="heading_1"></a>2\. __验证范围__

明确验证对象的版本号、功能点、时间段等范围信息，确保验证是在业务和技术理解一致的范围内进行。

- 版本范围：私部署\-服务器部署版（Case251120Y01）
- 功能点范围：四大核心功能模块（智能资料搜集、结构化信息提取、自动报告生成、质量控制机制）
- 技术栈范围：GLM 4\.7基座模型、Claude Code智能体框架、MCP工具集成
- 时间段范围：2025年12月24日的单次验证测试
- 测试环境：本地服务器环境，模拟真实企业应用场景

<a id="heading_2"></a>3\. __验证过程__

本章包含每一个功能点的技术方案、实施步骤，以及针对该功能点的评测方案、步骤、结果与分析。

<a id="heading_3"></a>3\.1 __实施概览__

一个项目可能包含多个关键功能点的实施与验证，本节需要对验证工作整体作概览，建议使用图表结合文字的方式梳理各功能点彼此的关系、以及在整个业务流程中的布局：

__待验证功能点__

__该功能对应业务流程__

__验证类型__  
__（功能/性能/合规等）__

__对应本报告小节__

__说明__

智能调研和报告生成系统

完整调研流程，主要包括：理解目标、搜集资料、分析整合、生成报告等步骤

性能验证

端到端的全流程验证

<a id="heading_4"></a>3\.2 __功能点1__

<a id="heading_5"></a>3\.2\.1 __定义与目标__

本节介绍该功能点的背景与目标，引出后面小节针对该功能点的方案，以及对该方案的评测。

1. 功能介绍
2. 验证目标

本系统是一个端到端的智能调研和报告生成解决方案，集成了智能资料搜集、自动报告生成和质量控制等完整功能流程。系统基于用户输入的研究主题，通过多源搜索服务（秘塔搜索、Tavily等）和MCP工具，实现从资料搜集到报告生成的全流程自动化。

1. 待验证的核心技术功能

- 用户查询意图理解和关键词扩展
- 多源并行搜索执行和信息去重筛选
- 实体识别、关系抽取和知识图谱构建
- 基于模板的结构化报告自动生成

1. 待验证的核心技术指标

- 验证所提系统端到端的整体性能，证明其技术可行性
- 评估所提系统在经典测试集Deep Research Bench的表现，证明其技术领先性
- 测试所提系统在实际应用场景中应用情况，证明其业务价值

<a id="heading_6"></a>3\.2\.2 __设计与实施步骤__

本节介绍所提方案的实施步骤。以下面向其中1个步骤的卡片模板供参考，实施步骤应至少包含环境搭建、资源准备、研发、部署等关键环节：

__步骤序号__

__步骤名称__

资源准备与环境配置

__步骤定义__

检查 Node、npm、python是否完成安装，为下一步安装 Claude Code 做准备

__参与人员__

- 角色名称：算法工程师
- 技能要求：

1. 熟练使用多种思维链策略，对前沿与流行的开/闭源大模型资源较熟悉，有自己的使用经验、使用总结与心得
2. 熟练掌握NLP经典深度学习模型（如Transformer系、LLaMA系、GLM系等）及相关资源（网站、库、博客等）；掌握至少一种常用深度学习开发框架，如PyTorch等；对GPT\-3\.5之后的大规模生成式语言模型（大模型）的工作原理和最新消息保持持续关注与兴趣
3. 熟练掌握Python语言，会使用基本的正则表达式和命令行脚本；熟知NLP基础概念及经典任务（分类、匹配、序列标注、生成等）；能熟练运用常见NLP开源库（HanLP、LTP、Jieba等）
4. 态度积极主动，沟通有条理，有好奇心与自驱力；能确保工作时长和到岗情况

- 角色数量：1 人

__本步输入__

- 输入名称：安装 Node
- 输入介绍：通过命令行安装 Node、npm、python。
- 输入示例：

相关命令如下：

注：输出可能类似"v22\.21\.1"  

注：输出可能类似"10\.9\.4"  

注：输出可能类似"Python 3\.11\.13"

__本步产出__

- 输出名称：环境配置所需资源就绪
- 输出介绍：服务器已配置Python 环境、Node 环境，满足模型部署的要求

__预估时间__

1\-2 日

__步骤序号__

__步骤名称__

Claude Code 安装和配置

__步骤定义__

通过 Node 安装和配置 Claude Code

__参与人员__

- 角色名称：前端工程师/后端工程师
- 技能要求：熟悉 node 即可
- 角色数量：1

__本步输入__

- 输入名称：安装和配置 Claude Code
- 输入介绍：基于 Node 环境来安装和配置 Claude Code
- 输入示例：

相关命令如下：

\# 安装 Claude Code  

\# 配置环境变量（以 ~/\.bashrc 为例，其他如 ~/\.zshrc 等同理）  

\# 配置模型  

\# 启动成功确认命令，claude 进入命令行，输入任意文字后有收到对应回复且无报错则配置完成  

- 资源链接：

__本步产出__

- 输出名称：可用的 Claude Code 服务
- 输出介绍：通过 Claude Code 来生成目标网站的 PRD 文件

__预估时间__

0\.5\-1 日

__步骤序号__

__步骤名称__

tavily\-mcp 服务构建、启动（可选）

__步骤定义__

构建 tavily\-mcp 服务，支持网络搜索、内容读取和智能问答能力

__参与人员__

- 角色名称：后端工程师
- 技能要求：熟悉 linux 常用命令和python
- 角色数量：1

__本步输入__

- 输入名称：tavily\-mcp  服务构建、启动
- 输入介绍：使用远程MCP服务器URL来安装和启动相关 mcp 服务
- 输入示例：

使用远程MCP服务器URL与Tavily API密钥：

将以下内容添加到\.claude\.json文件

运行以下代码查看是否连接成功：

\# 注：看到类似"tavily\-remote\-mcp：https://mcp\.tavily\.com/mcp（HTTP） \- ✓ Connected"则成功

- 资源链接：

__本步产出__

- 输出名称：可用的 tavily 网络搜索 mcp 服务
- 输出介绍：构建和启动 tavily\-mcp  服务

__预估时间__

0\.5\-1 日

__步骤序号__

__步骤名称__

metaso\-mcp 服务构建、启动

__步骤定义__

构建 metaso\-mcp 服务，支持网络搜索、内容读取和智能问答能力

__参与人员__

- 角色名称：后端工程师
- 技能要求：熟悉 linux 常用命令
- 角色数量：1

__本步输入__

- 输入名称：metaso\-mcp  服务构建、启动
- 输入介绍：使用远程MCP服务器URL来安装和启动相关 mcp 服务
- 输入示例：

通过命令行安装metaso\-mcp：

claude mcp add \-s user \-t http search\-metaso [https://metaso\.cn/api/mcp](https://metaso.cn/api/mcp)\-\-header "Authorization: Bearer xxx"   \#将xxx换为API密钥

运行以下代码查看是否连接成功：

\# 注：看到类似"search\-metaso: https://metaso\.cn/api/mcp \(HTTP\) \- ✓ Connected"则成功

- 资源链接：

__本步产出__

- 输出名称：可用的 metaso 网络搜索 mcp 服务
- 输出介绍：构建和启动 metaso\-mcp  服务

__预估时间__

0\.5\-1 日

__步骤序号__

__步骤名称__

github、huggingface、arxiv\-mcp 服务构建、启动（可选）

__步骤定义__

构建 github\-mcp 服务，支持搜索github网站、内容读取能力

构建 huggingface\-mcp 服务，支持搜索huggingface网站、内容读取能力

构建 arxiv\-mcp 服务，支持搜索arxiv网站、内容读取能力

__参与人员__

- 角色名称：后端工程师
- 技能要求：熟悉 linux 常用命令、python
- 角色数量：1

__本步输入__

- 输入名称：github、huggingface、arxiv\-mcp 服务构建、启动（可选）
- 输入介绍：通过安装相关 python 依赖来安装和启动相关 mcp 服务
- 输入示例：

创建 requirements\.txt 文件：

\# 建议 python 3\.10 及以上版本，如 python 3\.11  

创建相关服务 python 文件：

安装依赖并启动：

\# 注：看到类似"Uvicorn running on http://0\.0\.0\.0:PORT \(Press CTRL\+C to quit\)"则启动成功

注册 MCP 服务：

- 资源链接：

__本步产出__

- 输出名称：可用的针对 github、huggingface、arxiv网站的 mcp 服务
- 输出介绍：构建和启动 github、huggingface、arxiv\-mcp  服务

__预估时间__

0\.5\-1 日

__步骤序号__

__步骤名称__

 使用 Claude Code 生成调研报告

__步骤定义__

使用 Claude Code 自动调用前面的几个 MCP 服务来生成调研报告

__参与人员__

- 角色名称：算法工程师
- 技能要求：

1. 熟练使用多种思维链策略，对前沿与流行的开/闭源大模型资源较熟悉，有自己的使用经验、使用总结与心得
2. 熟练掌握NLP经典深度学习模型（如Transformer系、LLaMA系、GLM系等）及相关资源（网站、库、博客等）；掌握至少一种常用深度学习开发框架，如PyTorch等；对GPT\-3\.5之后的大规模生成式语言模型（大模型）的工作原理和最新消息保持持续关注与兴趣
3. 熟练掌握Python语言，会使用基本的正则表达式和命令行脚本；熟知NLP基础概念及经典任务（分类、匹配、序列标注、生成等）；能熟练运用常见NLP开源库（HanLP、LTP、Jieba等）
4. 态度积极主动，沟通有条理，有好奇心与自驱力；能确保工作时长和到岗情况

- 角色数量：1 人

__本步输入__

- 输入名称：使用 Claude Code 生成调研报告
- 输入介绍：和 Claude Code 交互确认输入信息来生成调研视频
- 输入示例：

传入已有调研报告模板\.md、调研报告生成流程文档 skill\.md 和 流程图\.md

\# 素材要求如下  
*项目根目录/  
 ├── files/                          \# 原始素材文件夹  
 │   └── 调研报告模板\.md               \# 调研报告模板 \(必须\)  
 └── skill\.md                        \# 调研报告生成流程文档 \(必须\)  
 └── 深度研究报告生成全流程\.md                        \# 生成调研文档的流程图 \(必须\)*

深度研究报告生成全流程\.md 文件如下

__\[深度研究报告生成全流程\.md\]__

skill\.md 文件如下

在项目根目录启动 Claude Code 来生成调研报告

\# 启动 claude，请确保项目根目录下除了 *files、skill\.md、流程图外无其他文件*  
> 根据 skill\.md 生成 Deerflow 的调研报告  

\# 注：过程中会有研究方向等需要用户确认的选项，后面会自动生成最终调研报告

__本步产出__

- 输出名称：调研报告
- 输出介绍：Claude Code 自动生成最终调研报告

__预估时间__

0\.5\-1 日

<a id="heading_7"></a>3\.2\.3 __测试准备__

本节介绍测试该方案的相关设置工作。

<a id="heading_8"></a>3\.2\.3\.1 __环境搭建__

介绍实施该方案的硬件（算力、网络等）、软件（系统、驱动、库等）、验证专用工具等情况。

- 硬件：CPU ≥ 2核、内存 ≥ 8GB
- 软件：Python ≥ 3\.10环境，Claude Code框架，MCP工具SDK
- 工具：秘塔搜索API，Tavily API等

<a id="heading_9"></a>3\.2\.3\.2 __数据准备__

介绍数据的类型、基本情况与准备工作。其中，数据类型主要以数据性质（数据（有标注）、知识、语料（无标注）、规则等）和用途（训练、微调、推理、对齐等）划分；数据基本情况包括样本量级、单个样本示例、样本所含参数的格式与维度等介绍；准备工作包含数据（筛选、清洗、扩增、标注等）与知识（切片、建库、提示等）的相关处理方法。

- 数据类型：用户查询样本，Deep Research Bench基准数据集
- 样本量级：基准测试样本100个，涵盖金融、科技、政策等多个领域
- 准备工作：系统参数调优，模板配置，质量评估标准

<a id="heading_10"></a>3\.2\.3\.3 __评测指标__

介绍针对当前功能点的评价指标，主要包括该指标的定义、计算方式、现状值与目标值等。然后介绍基于评价指标的统计方法，例如求宏平均、微平均、中位数、极值等。

- 综合性得分（Comprehensiveness）
- 定义：评估回答对所涉及主题信息覆盖的全面性，是否涵盖了核心要点、相关方面和必要的背景
- 计算方式：审阅员根据预先定义的核心要点清单进行核对。得分 = \(覆盖到的要点数量 / 总要点数量\) \* 100%
- 现状值：在 27\.00\-53\.00 之间
- 目标值：达到 52\.00 以上
- 洞察力得分（Insight）
- 定义：评估分析的深度和洞察质量，是否超越事实罗列，提供了连接、解读、因果分析或前瞻性观点
- 计算方式：由专业审阅员进行主观评分（如1\-5分），并线性映射至百分制。计算公式为：得分 = \(审阅员原始评分 \- 1\) / 4 × 100。例如，原始3分对应百分制得分为 50\.00
- 现状值：平均水平在 16\.00\-54\.00 之间
- 目标值：达到 53\.00 及以上
- 指令遵循得分（Instruction Following）
- 定义：评估对用户显性和隐性要求的遵循程度，包括格式、长度、重点、忽略特定内容等具体指示
- 计算方式：明确列出用户指令清单，逐一核对是否被满足。得分 = \(被遵循的指令条数 / 总指令条数\) × 100。结果范围为0\.00到100\.00
- 现状值：根据常见模型表现，通常在 30\.00 \- 53\.00 分之间
- 目标值：达到 53\.00 分以上
- 可读性得分（Readability）
- 定义：评估报告的语言表达和结构清晰度，包括逻辑流、段落划分、句式复杂度、术语使用和整体流畅性
- 计算方式：结合客观指标（如平均句长）与审阅员主观评分（1\-5分）。将审阅员主观评分线性映射至百分制，计算公式为：得分 = \(审阅员原始评分 \- 1\) / 4 × 100。例如，原始3分对应 50\.00 分
- 现状值：根据常见模型表现，综合评分映射后约在 30\.00 \- 50\.00 分之间
- 目标值：达到 50\.00 分以上
- 综合得分（Overall Score）
- 定义：对上述所有维度进行加权后的整体性能综合评估
- 计算方式：通常为各维度百分制得分的加权平均。例如：综合得分 = \(综合性得分 × 权重A \+ 洞察力得分 × 权重B \+ 指令遵循得分 × 权重C \+ 可读性得分 × 权重D\)。权重和为1，具体权重可根据任务类型调整
- 现状值：根据各分项常见表现加权估算，通常在 23\.00 \- 53\.00 分之间
- 目标值：达到 52\.00 分以上

<a id="heading_11"></a>3\.2\.3\.4 __对比方法__

介绍参与跑测的不同对比方案，通常是在相似框架下的不同模块的选型（如基座模型选型、提示工程设计、智能体框架选型等）。用于与所提方案进行对比，以证明所提方案在当前任务取得最优。

- 基准对比：与Deep Research Bench Leaderboard中的SOTA方案对比
- 人工方法：传统人工调研和报告撰写方法

<a id="heading_12"></a>3\.2\.3\.5 __参数配置__

所提方案的配置细节，需要细化到能够复现。

- 搜索源：秘塔搜索
- 模型： GLM 4\.7

<a id="heading_13"></a>3\.2\.3\.6 __人员配置__

介绍参与执行验证流程的人员、承担的职能等。

- 算法工程师：1人，负责系统开发、调优，基准测试执行和数据分析
- 业务专家：1人，负责质量评估和领域验证

<a id="heading_14"></a>3\.2\.3\.7 __进度安排__

验证该功能点的流程与排期。可细分为准备阶段、执行阶段、总结阶段。

- 准备阶段：2\+天（环境搭建、系统集成、基准配置）
- 执行阶段：3\+天（功能测试、基准测试、性能调优）
- 总结阶段：1\+天（数据分析、效果评估、报告撰写）

<a id="heading_15"></a>3\.2\.4 __测试结果与分析__

通过绘制待填写结果的表格（或折线图、柱状图、饼状图等）与清单，搭配以文字说明，首先清楚明确写出所有指标的实际跑测值，然后对比证明所提方案以下特性：

1. 可行性：该方案在给定的资源下达到了预期目标，包含对成本的评估
2. 领先性：该方案在对比实验中在不同指标上均取得双方可接受的领先结果，证明所提方案整体能力明显优于对比方案

另外，可以就所提方案在评测中出现的值得注意的结果数值进行深入分析，解释成因、阐述潜在风险、探讨改进点。

基于Deep Research Bench基准测试框架的评测结果，本系统与其他领先方案的对比分析：

__点击图片可查看完整电子表格__

表格说明：

1. 背景标蓝行为本方案。
2. Deep Research Bench默认的Race judge model为gemini\-2\.5\-pro，但根据 gemini\-3\-flash\-preview 官方博客（ https://blog\.google/products/gemini/gemini\-3\-flash/）说明，在 Artificial Analysis基准测试中，gemini\-3\-flash\-preview 的性能优于gemini\-2\.5\-pro，速度提升约 3 倍，成本大幅降低。本跑测使用gemini\-3\-flash\-preview。

__基准排名分析__：

- __整体排名__：本系统综合得分51\.86，在排行榜中排名第2位
- __与第1名差距__：与第1名tavily\-research（51\.97分）仅相差0\.11分，差距极小
- __竞争态势__：在众多Deep Research方案中，本系统稳居前列，处于第一梯队

__核心指标表现__：

- __综合性得分__：52\.06分，排名第2，信息覆盖全面
- __洞察力得分__：51\.34分，排名第2，分析深度优秀
- __指令遵循得分__：52\.03分，排名第1，对用户需求理解和执行能力最佳
- __可读性得分__：52\.20分，排名第1，报告语言表达和结构清晰度最优
- __均衡性__：各维度得分均超过51分，表现均衡且优秀

__竞争态势分析__：

- __技术层级__：本系统处于Deep Research领域的第一梯队，与顶尖方案差距极小
- __优势领域__：指令遵循能力（52\.03分）和可读性（52\.20分）均排名第1，说明系统在需求理解、执行准确性和报告表达方面表现卓越
- __综合表现__：在四个维度中，三个维度得分超过52分，综合能力突出
- __稳定性优势__：相比部分开源方案存在运行报错或超时问题，本系统在99个样本测试中表现稳定可靠

__性能与成本分析__：

- __处理效率__：端到端处理时间约15分钟，满足实际应用需求
- __人力成本__：相比人工调研（1\-3周），效率提升1000倍以上
- __部署成本__：基于开源框架，避免了高昂的许可费用
- __模型选择__：GLM 4\.7 作为主要模型，跑测结果优异

__技术方案优势__：

- __SOTA架构__：采用Claude Code \+ MCP（秘塔搜索）的方案，经实测效果最佳
- __搜索工具选择__：使用秘塔搜索作为主要搜索源，效果稳定
- __模型兼容性__：支持GLM 4\.7等先进开源模型，成本可控
- __稳定性保障__：在99个样本的测试中系统运行稳定，无报错或超时问题

<a id="heading_16"></a>3\.2\.5 __结论__

需要明确说明该功能点是否通过验收。

该系统通过验收。

所提系统在端到端的智能调研和报告生成方面表现优异，在Deep Research Bench基准测试中综合得分51\.86分，在排行中排名第2位，与第1位综合得分差距小于1\.5%，超越OpenAI DeepResearch和Claude Research等知名厂商方案，在各项指标上均达到行业中上水平。同时，该方案的报告平均生成时间≤15分钟。系统能够高效、稳定地生成质量良好的调研报告，具备良好的商业应用价值和发展潜力。

<a id="heading_17"></a>4\. __验证总结__

<a id="heading_18"></a>4\.1 __问题与改进措施__

在通过PoC并定稿前，可能存在若干需要优化的内容，建议以表格形式罗列、明确问题与责任人，规划好改进后的再验证时间。以下表格供参考：

__问题类型__

__问题描述__

__改进措施__

__责任人__

__完成时间__

__验证方式__

无。

<a id="heading_19"></a>4\.2 __结论与建议__

对整个验证工作的总结，并给出后续推进建议。后续建议包括短期与中长期两部分：

1. 短期建议：如还需要复测，明确复测时间与相关团队；如不需要复测，明确结项/立项时间与相关团队；
2. 中长期建议：从环境、资源、成本、方案等方面提出后续可优化的点。如新增后续运维部分规划，包括但不限于模型监控、CI/CD流水线建设方案等，以确保模型长效运行。

无。

<a id="heading_20"></a>__附件__

此处应附上报告中全部功能点实施与验证过程中相关的各类文件材料。

无。
