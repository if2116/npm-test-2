#### English

# Technical Configuration

__Step Number__

1

__Step Name__

Resource Preparation and Environment Configuration

__Step Definition__

Check if Node, npm, and python are installed to prepare for the next step of installing Claude Code

__Participants__

- Role Name: Algorithm Engineer
- Skill Requirements:

1. Proficient in using various chain-of-thought strategies, familiar with cutting-edge and popular open/closed source LLM resources, with own usage experience, summaries, and insights
2. Proficient in NLP classic deep learning models (such as Transformer series, LLaMA series, GLM series, etc.) and related resources (websites, libraries, blogs, etc.); master at least one common deep learning development framework, such as PyTorch; maintain continuous attention and interest in the working principles and latest news of large-scale generative language models (LLMs) after GPT-3.5
3. Proficient in Python language, able to use basic regular expressions and command-line scripts; familiar with NLP basic concepts and classic tasks (classification, matching, sequence labeling, generation, etc.); able to skillfully use common NLP open-source libraries (HanLP, LTP, Jieba, etc.)
4. Proactive attitude, organized communication, curious and self-driven; can ensure working hours and attendance

- Role Quantity: 1 person

__Step Input__

- Input Name: Install Node
- Input Introduction: Install Node, npm, python via command line.
- Input Example:

```text
node -v
Note: Output may be similar to "v22.21.1"

npm -v
Note: Output may be similar to "10.9.4"

python -V
Note: Output may be similar to "Python 3.11.13"
```

__Step Output__

- Output Name: Environment configuration resources ready
- Output Introduction: Server has configured Python environment and Node environment, meeting model deployment requirements

__Estimated Time__

1-2 days

__Step Number__

2

__Step Name__

Claude Code Installation and Configuration

__Step Definition__

Install and configure Claude Code through Node

__Participants__

- Role Name: Algorithm Engineer (Frontend Engineer/Backend Engineer)
- Skill Requirements: Familiar with node
- Role Quantity: 1 person

__Step Input__

- Input Name: Install and configure Claude Code
- Input Introduction: Install and configure Claude Code based on Node environment
- Input Example:

```bash
# Install Claude Code
npm install -g @anthropic-ai/claude-code

# Configure environment variables (using ~/.bashrc as an example)
echo 'export ANTHROPIC_BASE_URL="YOUR_BASE_URL"' >> ~/.bashrc
echo 'export ANTHROPIC_AUTH_TOKEN="YOUR_AUTH_TOKEN"' >> ~/.bashrc

# Configure models
vim ~/.claude/settings.json
{
  "env": {
    "ANTHROPIC_DEFAULT_HAIKU_MODEL": "YOUR_HAIKU_MODEL",
    "ANTHROPIC_DEFAULT_SONNET_MODEL": "YOUR_SONNET_MODEL",
    "ANTHROPIC_DEFAULT_OPUS_MODEL": "YOUR_OPUS_MODEL"
  }
}

# Test Claude Code
claude
> your_input
```

- Resource Links:
  - Claude Code GitHub: https://github.com/anthropics/claude-code

__Step Output__

- Output Name: Available Claude Code service
- Output Introduction: Use Claude Code to generate research reports

__Estimated Time__

0.5-1 day

__Step Number__

3

__Step Name__

tavily-mcp Service Construction and Startup (Optional)

__Step Definition__

Build tavily-mcp service to support web search, content reading and intelligent Q&A capabilities

__Participants__

- Role Name: Algorithm/Backend Engineer
- Skill Requirements: Familiar with Linux common commands and python
- Role Quantity: 1 person

__Step Input__

- Input Name: tavily-mcp service construction and startup
- Input Introduction: Use remote MCP server URL to install and start related MCP services
- Input Example:

```text
https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>
```

Add the following content to .claude.json file:

```text
{
  "mcpServers": {
    "tavily-remote-mcp": {
      "command": "npx -y mcp-remote https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>",
      "env": {}
    }
  }
}
```

Run the following code to check if connection is successful:

```text
claude mcp list
# Note: Seeing "tavily-remote-mcp: https://mcp.tavily.com/mcp (HTTP) - ✓ Connected" indicates success
```

- Resource Links:
  - Claude Code GitHub: https://github.com/anthropics/claude-code

__Step Output__

- Output Name: Available tavily web search MCP service
- Output Introduction: Build and start tavily-mcp service

__Estimated Time__

0.5-1 day

__Step Number__

4

__Step Name__

metaso-mcp Service Construction and Startup

__Step Definition__

Build metaso-mcp service to support web search, content reading and intelligent Q&A capabilities

__Participants__

- Role Name: Algorithm/Backend Engineer
- Skill Requirements: Familiar with Linux common commands
- Role Quantity: 1 person

__Step Input__

- Input Name: metaso-mcp service construction and startup
- Input Introduction: Use remote MCP server URL to install and start related MCP services
- Input Example:

```text
claude mcp add -s user -t http search-metaso https://metaso.cn/api/mcp --header "Authorization: Bearer xxx"  # Replace xxx with API key
```

Run the following code to check if connection is successful:

```text
claude mcp list
# Note: Seeing "search-metaso: https://metaso.cn/api/mcp (HTTP) - ✓ Connected" indicates success
```

- Resource Links:
  - Claude Code GitHub: https://github.com/anthropics/claude-code

__Step Output__

- Output Name: Available metaso web search MCP service
- Output Introduction: Build and start metaso-mcp service

__Estimated Time__

0.5-1 day

__Step Number__

5

__Step Name__

github, huggingface, arxiv-mcp Service Construction and Startup (Optional)

__Step Definition__

Build github-mcp service to support GitHub website search and content reading capabilities
Build huggingface-mcp service to support HuggingFace website search and content reading capabilities
Build arxiv-mcp service to support arXiv website search and content reading capabilities

__Participants__

- Role Name: Algorithm/Backend Engineer
- Skill Requirements: Familiar with Linux common commands, python
- Role Quantity: 1 person

__Step Input__

- Input Name: github, huggingface, arxiv-mcp service construction and startup (optional)
- Input Introduction: Install and start related MCP services by installing related Python dependencies
- Input Example:

Create requirements.txt file:

```text
# Recommend python 3.10 and above, such as python 3.11

loguru>=0.7.0
python-dotenv>=1.0.0
mcp>=1.0.0
```

Create related service Python files:

```text
__github_server.py__
__hf_server.py__
__arxiv_server.py__
```

Install dependencies and start:

```text
pip install -r requirements.txt
python github_server.py
python hf_server.py
python arxiv_server.py

# Note: Seeing "Uvicorn running on http://0.0.0.0:PORT (Press CTRL+C to quit)" indicates successful startup
```

Register MCP services:

```text
# arxiv
claude mcp add -s user -t sse paper-arxiv http://127.0.0.1:4002/sse
# github
claude mcp add -s user -t sse code-github http://127.0.0.1:4001/sse
# huggingface
claude mcp add -s user -t sse model-huggingface http://127.0.0.1:4003/sse
```

- Resource Links:
  - mcp-python-sdk GitHub: https://github.com/modelcontextprotocol/python-sdk

__Step Output__

- Output Name: Available MCP services for GitHub, HuggingFace, arXiv websites
- Output Introduction: Build and start github, huggingface, arxiv-mcp services

__Estimated Time__

0.5-1 day

__Step Number__

6

__Step Name__

Use Claude Code to Generate Research Reports

__Step Definition__

Use Claude Code to automatically call the previous MCP services to generate research reports

__Participants__

- Role Name: Algorithm Engineer
- Skill Requirements:

1. Proficient in using various chain-of-thought strategies, familiar with cutting-edge and popular open/closed source LLM resources, with own usage experience, summaries, and insights
2. Proficient in NLP classic deep learning models (such as Transformer series, LLaMA series, GLM series, etc.) and related resources (websites, libraries, blogs, etc.); master at least one common deep learning development framework, such as PyTorch; maintain continuous attention and interest in the working principles and latest news of large-scale generative language models (LLMs) after GPT-3.5
3. Proficient in Python language, able to use basic regular expressions and command-line scripts; familiar with NLP basic concepts and classic tasks (classification, matching, sequence labeling, generation, etc.); able to skillfully use common NLP open-source libraries (HanLP, LTP, Jieba, etc.)
4. Proactive attitude, organized communication, curious and self-driven; can ensure working hours and attendance

- Role Quantity: 1 person

__Step Input__

- Input Name: Use Claude Code to generate research reports
- Input Introduction: Interact with Claude Code to confirm input information to generate research reports
- Input Example:

Pass in existing research report template.md, research report generation process document skill.md and flowchart.md

```text
Project root directory/
├── files/                          # Original material folder
│   └── Research Report Template.md               # Research report template (required)
├── skill.md                        # Research report generation process document (required)
└── Deep Research Report Generation Full Process.md                        # Flowchart for generating research documents (required)
```

Deep Research Report Generation Full Process.md file content:

```text
__Deep Research Report Generation Full Process.md__
```

skill.md file content:

```text
__SKILL.md__
```

Start Claude Code in the project root directory to generate research reports:

```text
# Start claude, please ensure there are no other files in the project root directory except *files, skill.md, flowchart
claude
> Generate research report based on skill.md

# Note: There will be options requiring user confirmation during the process, and the final research report will be automatically generated later
```

__Step Output__

- Output Name: Research report
- Output Introduction: Claude Code automatically generates the final research report

__Estimated Time__

0.5-1 day

---

#### 中文

# 技术配置

__步骤序号__

1

__步骤名称__

资源准备与环境配置

__步骤定义__

检查 Node、npm、python是否完成安装，为下一步安装 Claude Code 做准备

__参与人员__

- 角色名称：算法工程师
- 技能要求：

1. 熟练使用多种思维链策略，对前沿与流行的开/闭源大模型资源较熟悉，有自己的使用经验、使用总结与心得
2. 熟练掌握NLP经典深度学习模型（如Transformer系、LLaMA系、GLM系等）及相关资源（网站、库、博客等）；掌握至少一种常用深度学习开发框架，如PyTorch等；对GPT-3.5之后的大规模生成式语言模型（大模型）的工作原理和最新消息保持持续关注与兴趣
3. 熟练掌握Python语言，会使用基本的正则表达式和命令行脚本；熟知NLP基础概念及经典任务（分类、匹配、序列标注、生成等）；能熟练运用常见NLP开源库（HanLP、LTP、Jieba等）
4. 态度积极主动，沟通有条理，有好奇心与自驱力；能确保工作时长和到岗情况

- 角色数量：1人

__本步输入__

- 输入名称：安装 Node
- 输入介绍：通过命令行安装 Node、npm、python。
- 输入示例：

```text
node -v
注意：输出可能类似于 "v22.21.1"

npm -v
注意：输出可能类似于 "10.9.4"

python -V
注意：输出可能类似于 "Python 3.11.13"
```

__本步产出__

- 输出名称：环境配置所需资源就绪
- 输出介绍：服务器已配置Python 环境、Node 环境，满足模型部署的要求

__预估时间__

1-2日

__步骤序号__

2

__步骤名称__

Claude Code 安装和配置

__步骤定义__

通过 Node 安装和配置 Claude Code

__参与人员__

- 角色名称：算法工程师（前端工程师/后端工程师）
- 技能要求：熟悉 node 即可
- 角色数量：1人

__本步输入__

- 输入名称：安装和配置 Claude Code
- 输入介绍：基于 Node 环境来安装和配置 Claude Code
- 输入示例：

```bash
# 安装 Claude Code
npm install -g @anthropic-ai/claude-code

# 配置环境变量（以 ~/.bashrc 为例，其他如 ~/.zshrc 类似）
echo 'export ANTHROPIC_BASE_URL="YOUR_BASE_URL"' >> ~/.bashrc
echo 'export ANTHROPIC_AUTH_TOKEN="YOUR_AUTH_TOKEN"' >> ~/.bashrc

# 配置模型
vim ~/.claude/settings.json
{
  "env": {
    "ANTHROPIC_DEFAULT_HAIKU_MODEL": "YOUR_HAIKU_MODEL",
    "ANTHROPIC_DEFAULT_SONNET_MODEL": "YOUR_SONNET_MODEL",
    "ANTHROPIC_DEFAULT_OPUS_MODEL": "YOUR_OPUS_MODEL"
  }
}

# 启动成功确认命令，claude 进入命令行，输入任意文本并收到相应回复不报错即配置完成
claude
> your_input
```

- 资源链接：
  - Claude Code GitHub：https://github.com/anthropics/claude-code

__本步产出__

- 输出名称：可用的 Claude Code 服务
- 输出介绍：通过 Claude Code 来生成调研报告

__预估时间__

0.5-1日

__步骤序号__

3

__步骤名称__

tavily-mcp 服务构建、启动（可选）

__步骤定义__

构建 tavily-mcp 服务，支持网络搜索、内容读取和智能问答能力

__参与人员__

- 角色名称：算法/后端工程师
- 技能要求：熟悉 linux 常用命令和python
- 角色数量：1人

__本步输入__

- 输入名称：tavily-mcp  服务构建、启动
- 输入介绍：使用远程MCP服务器URL来安装和启动相关 mcp 服务
- 输入示例：

使用远程MCP服务器URL与Tavily API密钥：

```text
https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>
```

将以下内容添加到.claude.json文件

```text
{
  "mcpServers": {
    "tavily-remote-mcp": {
      "command": "npx -y mcp-remote https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>",
      "env": {}
    }
  }
}
```

运行以下代码查看是否连接成功：

```text
claude mcp list

# 注意：看到类似 "tavily-remote-mcp: https://mcp.tavily.com/mcp (HTTP) - ✓ Connected" 表示成功
```

- 资源链接：
  - Claude Code GitHub：https://github.com/anthropics/claude-code

__本步产出__

- 输出名称：可用的 tavily 网络搜索 mcp 服务
- 输出介绍：构建和启动 tavily-mcp  服务

__预估时间__

0.5-1日

__步骤序号__

4

__步骤名称__

metaso-mcp 服务构建、启动

__步骤定义__

构建 metaso-mcp 服务，支持网络搜索、内容读取和智能问答能力

__参与人员__

- 角色名称：算法/后端工程师
- 技能要求：熟悉 linux 常用命令
- 角色数量：1人

__本步输入__

- 输入名称：metaso-mcp  服务构建、启动
- 输入介绍：使用远程MCP服务器URL来安装和启动相关 mcp 服务
- 输入示例：

通过命令行安装metaso-mcp：

```text
claude mcp add -s user -t http search-metaso https://metaso.cn/api/mcp --header "Authorization: Bearer xxx"   # 替换 xxx 为 API key
```

运行以下代码查看是否连接成功：

```text
claude mcp list

# 注意：看到类似 "search-metaso: https://metaso.cn/api/mcp (HTTP) - ✓ Connected" 表示成功
```

- 资源链接：
  - Claude Code GitHub：https://github.com/anthropics/claude-code

__本步产出__

- 输出名称：可用的 metaso 网络搜索 mcp 服务
- 输出介绍：构建和启动 metaso-mcp  服务

__预估时间__

0.5-1日

__步骤序号__

5

__步骤名称__

github、huggingface、arxiv-mcp 服务构建、启动（可选）

__步骤定义__

构建 github-mcp 服务，支持搜索github网站、内容读取能力
构建 huggingface-mcp 服务，支持搜索huggingface网站、内容读取能力
构建 arxiv-mcp 服务，支持搜索arxiv网站、内容读取能力

__参与人员__

- 角色名称：算法/后端工程师
- 技能要求：熟悉 linux 常用命令、python
- 角色数量：1人

__本步输入__

- 输入名称：github、huggingface、arxiv-mcp 服务构建、启动（可选）
- 输入介绍：通过安装相关 python 依赖来安装和启动相关 mcp 服务
- 输入示例：

创建 requirements.txt 文件：

```text
# 建议使用 python 3.10 及以上版本，如 python 3.11

loguru>=0.7.0
python-dotenv>=1.0.0
mcp>=1.0.0
```

创建相关服务 python 文件：

```text
__github_server.py__
__hf_server.py__
__arxiv_server.py__
```

安装依赖并启动：

```text
pip install -r requirements.txt
python github_server.py
python hf_server.py
python arxiv_server.py

# 注意：看到类似 "Uvicorn running on http://0.0.0.0:PORT (Press CTRL+C to quit)" 表示启动成功
```

注册 MCP 服务：

```text
# arxiv
claude mcp add -s user -t sse paper-arxiv http://127.0.0.1:4002/sse
# github
claude mcp add -s user -t sse code-github http://127.0.0.1:4001/sse
# huggingface
claude mcp add -s user -t sse model-huggingface http://127.0.0.1:4003/sse
```

- 资源链接：
  - mcp-python-sdk GitHub：https://github.com/modelcontextprotocol/python-sdk

__本步产出__

- 输出名称：可用的针对 github、huggingface、arxiv网站的 mcp 服务
- 输出介绍：构建和启动 github、huggingface、arxiv-mcp  服务

__预估时间__

0.5-1日

__步骤序号__

6

__步骤名称__

使用 Claude Code 生成调研报告

__步骤定义__

使用 Claude Code 自动调用前面的几个 MCP 服务来生成调研报告

__参与人员__

- 角色名称：算法工程师
- 技能要求：

1. 熟练使用多种思维链策略，对前沿与流行的开/闭源大模型资源较熟悉，有自己的使用经验、使用总结与心得
2. 熟练掌握NLP经典深度学习模型（如Transformer系、LLaMA系、GLM系等）及相关资源（网站、库、博客等）；掌握至少一种常用深度学习开发框架，如PyTorch等；对GPT-3.5之后的大规模生成式语言模型（大模型）的工作原理和最新消息保持持续关注与兴趣
3. 熟练掌握Python语言，会使用基本的正则表达式和命令行脚本；熟知NLP基础概念及经典任务（分类、匹配、序列标注、生成等）；能熟练运用常见NLP开源库（HanLP、LTP、Jieba等）
4. 态度积极主动，沟通有条理，有好奇心与自驱力；能确保工作时长和到岗情况

- 角色数量：1人

__本步输入__

- 输入名称：使用 Claude Code 生成调研报告
- 输入介绍：和 Claude Code 交互确认输入信息来生成调研视频
- 输入示例：

传入已有调研报告模板.md、调研报告生成流程文档 skill.md 和 流程图.md

```text
项目根目录/
├── files/                          # 原始素材文件夹
│   └── 调研报告模板.md               # 调研报告模板（必需）
├── skill.md                        # 调研报告生成流程文档（必需）
└── 深度研究报告生成全流程.md                        # 生成调研文档流程图（必需）
```

深度研究报告生成全流程.md 文件如下

```text
__深度研究报告生成全流程.md__
```

skill.md 文件如下

```text
__SKILL.md__
```

在项目根目录启动 Claude Code 来生成调研报告

```text
# 启动 claude，请确保项目根目录除了 *files, skill.md, flowchart 没有其他文件
claude
> 根据 skill.md 生成调研报告

# 注意：过程中会有需要用户确认的选项，如研究方向等，最后会自动生成最终调研报告
```

__本步产出__

- 输出名称：调研报告
- 输出介绍：Claude Code 自动生成最终调研报告

__预估时间__

0.5-1日
